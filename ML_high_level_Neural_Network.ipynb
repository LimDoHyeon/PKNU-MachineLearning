{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTkhhIVCfpIEAoILnqVhRF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimDoHyeon/PKNU-MachineLearning/blob/main/ML_high_level_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 다층 신경망의 한계점\n",
        "- 층을 깊이 쌓은 신경망은 더 정교한 기능을 하는 것이 아니라 학습을 못 하는 현상이 나타남\n",
        "  - 손실 함수의 경사를 계산하여 연결강도를 수정하는 일이 제대로 동작하지 않는 것\n",
        "  - 오차가 아래 단계(이전 단계)로 역전파될수록 점점 경사값 신호가 0으로 떨어지는(소실되는) **사라지는 경사(vanishing gradient)** 문제가 발생하기 때문\n",
        "  - 반대로, 기울기가 아래 단계로 내려가면서 급격히 커지며 하위 단계의 연결강도가 지나치게 커지게 되는 **폭발하는 경사(exploding gradient)** 문제도 존제\n",
        "\n",
        "- 문제 원인 분석\n",
        "  - sigmoid 함수는 양 끝으로 갈 수록 기울기, 즉 미분값이 0에 가까워지는데 오차 역전파는 미분값을 곱해 오차를 아래로 전달하는 것이므로, 활성화 함수가 포화 상태에 가까워질수록 오차 전파가 잘 이루어지지 않음\n",
        "\n",
        "- 이를 대체하기 위해 하이퍼볼릭 탄젠트(tanh)를 사용\n",
        "    - 이는 활성하 함수값이 0 부근인 곳에서도 미분치가 (보다)큰 값으로 유지됨\n",
        "    - 은닉층의 결과가 0인 상태에 도달해도 오차를 잘 전파한다\n",
        "  \n",
        "- 이러한 이유로 여러 층을 겹처 신경망을 구현할 때 시그모이드에서 탈피해 다양한 활성화 함수를 사용하기 시작함\n",
        "- 새로운 활성화 함수들은 생물 신경세포 모방 보다는 계산상의 이점을 강화하는 방향으로 발전함"
      ],
      "metadata": {
        "id": "N-hBMDrl9V1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 심층 신경망 학습의 돌파구 - 연결강도 초기화\n",
        "- 일반적으로 사용되는 균일 분포의 난수를 이용해 연결강도를 정규화할 경우\n",
        "  - 각 계층의 노드 수가 달라지면 입력에서  출력으로 가는 순전파 신호와, 출력에서 입력으로 내려오는 **오차 역전파 신호의 분산이 왜곡**되어 전달됨 -> 사라지는 경사/폭발하는 경사 문제 발생\n",
        "- 이러한 문제를 피하기 위해서는 **각 은닉층의 크기가 동일해야 한다**\n",
        "  - 서로 다른 크기의 층을 연결해야 할 수도 있다.\n",
        "  - 이러한 연결강도 초기화 방법을 글로럿 초기화(glorot initialization) 또는 세이비어 초기화(Xavier initialization)이라고 부름\n",
        "  - **텐서플로우의 케라스 API는 일반적으로 글로럿 초기화를 디폴트 초기화 방법으로 사용\n",
        "      \n",
        "<참고>\n",
        "- 논리장치에 입력되는 신호의 개수를 '팬-인'이라 부름\n",
        "- 연산이 끝나고 출력되는 신호의 개수를 '팬 아웃'이라 부름\n"
      ],
      "metadata": {
        "id": "-8kM6TadH3t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 활성화 함수의 다양화\n",
        "> 주로 ReLU와 그 변형들을 사용 -> 이들이 오차 기울기를 잘 전달할 수 있는 것으로 알려짐\n",
        "\n",
        "1. leaky(새는) ReLU 함수\n",
        "  - 입력이 음수인 곳에서도 0을 출력하지 않고 1보다 작은 기울기로 약간의 신호를 내어 보냄\n",
        "  - 이 구간의 미분은 a가 되고, 이 값은 0이 아니기 때문에 오차를 내려 보내어 연결강도 조정하는 일이 가능\n",
        "\n",
        "2. ELU 모델\n",
        "  - 음수 구간에서 선형 모델을 사용하지 않고 지수 함수를 사용\n",
        "    - a = 1이면 어디서나 미분 가능 (장점)\n",
        "    - 계산 비용이 ReLU보다 큼 (단점)\n"
      ],
      "metadata": {
        "id": "7ndxkLLqLWTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.4 텐서플로우로 시작하는 Hello world - MNIST 예제"
      ],
      "metadata": {
        "id": "v8xj_0mMM2GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('x_train 데이터의 형태: ', x_train.shape)\n",
        "print('x_train[0] 데이터의 형태:', x_train[0].shape)\n",
        "print('y_train 데이터의 형태:', y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHBZ1zxtRD6_",
        "outputId": "4b19f476-b0be-483b-8bd1-3ba24f5dcd46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "x_train 데이터의 형태:  (60000, 28, 28)\n",
            "x_train[0] 데이터의 형태: (28, 28)\n",
            "y_train 데이터의 형태: (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = x_train[0]\n",
        "for i in range(28):\n",
        "  for j in range(28):\n",
        "    print('{:4d}'.format(num[i][j]), end='')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frYN6LHzRjmb",
        "outputId": "b489eb62-8262-4306-ad90-91a4fa818981"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0\n",
            "   0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(num, cmap='Greys', interpolation='nearest') #nearest 보간한 회색조 영상\n",
        "print('y_train[0] =', y_train[0]) #데이터의 의미/유형/명칭/레이블 등"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ydqu9V9LR0xP",
        "outputId": "fb586136-3c0d-4620-ca8b-5a917090eb32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0] = 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOTklEQVR4nO3dfYxUZZbH8d8RQVSIQWk7xCHbsxM1MSbTgyVZw0tYxiXIP2AwZkicsJFsT3xJBkPMGDZxfEkMMcuMGM0kPQvCbGYdRwHBxOyihMSQ6GipqIDvpgmNvDRRGSHKLHD2j75MWqx6qqm6Vbfo8/0knaq6p27fQ8GPW3Wfe+sxdxeAke+8ohsA0BqEHQiCsANBEHYgCMIOBHF+Kzc2ceJE7+rqauUmgVD6+vp0+PBhq1RrKOxmNlfSKkmjJP2nu69IPb+rq0vlcrmRTQJIKJVKVWt1v403s1GSnpR0k6RrJC0ys2vq/X0AmquRz+xTJX3i7p+5+98k/UnS/HzaApC3RsJ+haS9Qx73Z8u+w8x6zKxsZuWBgYEGNgegEU0/Gu/uve5ecvdSR0dHszcHoIpGwr5P0uQhj3+QLQPQhhoJ+xuSrjSzH5rZGEk/k7Q5n7YA5K3uoTd3P2Fmd0v6Xw0Ova1x9125dQYgVw2Ns7v7i5JezKkXAE3E6bJAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0dAsrmh/p06dStaPHz/e1O2vW7euau3YsWPJdXfv3p2sP/bYY8n68uXLq9aeeOKJ5LoXXnhhsr5y5cpk/Y477kjWi9BQ2M2sT9LXkk5KOuHupTyaApC/PPbs/+zuh3P4PQCaiM/sQBCNht0lbTGzN82sp9ITzKzHzMpmVh4YGGhwcwDq1WjYp7v7FEk3SbrLzGae+QR373X3kruXOjo6GtwcgHo1FHZ335fdHpK0UdLUPJoCkL+6w25mF5vZ+NP3Jc2RtDOvxgDkq5Gj8Z2SNprZ6d/z3+7+P7l0NcIcOXIkWT958mSy/s477yTrW7ZsqVr76quvkuv29vYm60Xq6upK1pctW5asr169umrtkksuSa47Y8aMZH327NnJejuqO+zu/pmkH+fYC4AmYugNCIKwA0EQdiAIwg4EQdiBILjENQf9/f3Jend3d7L+5Zdf5tnOOeO889L7mtTQmVT7MtQlS5ZUrV1++eXJdceNG5esn4tng7JnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPwWWXXZasd3Z2JuvtPM4+Z86cZL3Wn33Dhg1VaxdccEFy3VmzZiXrODvs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZc1Druuq1a9cm688991yyfsMNNyTrCxcuTNZTpk+fnqxv2rQpWR8zZkyyfuDAgaq1VatWJddFvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ5u4t21ipVPJyudyy7Z0rjh8/nqzXGstevnx51dqjjz6aXHfbtm3J+syZM5N1tJdSqaRyuWyVajX37Ga2xswOmdnOIcsuNbOXzOzj7HZCng0DyN9w3savlTT3jGX3Sdrq7ldK2po9BtDGaobd3V+R9MUZi+dLWpfdXydpQc59AchZvQfoOt19f3b/gKSqX7JmZj1mVjaz8sDAQJ2bA9Coho/G++ARvqpH+dy9191L7l46FyfDA0aKesN+0MwmSVJ2eyi/lgA0Q71h3yxpcXZ/saT0dZAAClfzenYze1rSLEkTzaxf0q8lrZD0ZzNbImmPpFub2eRIV+v702uZMKH+kc/HH388WZ8xY0ayblZxSBdtqGbY3X1RldJPc+4FQBNxuiwQBGEHgiDsQBCEHQiCsANB8FXSI8DSpUur1l5//fXkuhs3bkzWd+3alaxfe+21yTraB3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYRIPVV0729vcl1t27dmqzPnz8/WV+wIP31g9OmTatau/nmm5PrcvlsvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQTNkcXK3r3efOPXNOz+86cuRI3dtes2ZNsr5w4cJkfdy4cXVve6RqaMpmACMDYQeCIOxAEIQdCIKwA0EQdiAIwg4EwfXswU2dOjVZr/W98ffcc0+y/uyzz1at3X777cl1P/3002T93nvvTdbHjx+frEdTc89uZmvM7JCZ7Ryy7AEz22dmO7Kfec1tE0CjhvM2fq2kSqdR/dbdu7OfF/NtC0Deaobd3V+R9EULegHQRI0coLvbzN7N3uZPqPYkM+sxs7KZlQcGBhrYHIBG1Bv230n6kaRuSfslraz2RHfvdfeSu5c6Ojrq3ByARtUVdnc/6O4n3f2UpN9LSh/SBVC4usJuZpOGPLxZ0s5qzwXQHmpez25mT0uaJWmipIOSfp097pbkkvok/cLd99faGNezjzzffvttsv7aa69Vrd14443JdWv927zllluS9WeeeSZZH4lS17PXPKnG3RdVWLy64a4AtBSnywJBEHYgCMIOBEHYgSAIOxAEl7iiIWPHjk3WZ82aVbU2atSo5LonTpxI1p9//vlk/cMPP6xau/rqq5PrjkTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkfT5558n6xs2bEjWX3311aq1WuPotVx//fXJ+lVXXdXQ7x9p2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs49wtabcevLJJ5P1p556Klnv7+8/656Gq9b17l1dXcm6WcVvVA6LPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4+zng6NGjyfoLL7xQtfbQQw8l1/3oo4/q6ikPs2fPTtZXrFiRrF933XV5tjPi1dyzm9lkM9tmZrvNbJeZ/TJbfqmZvWRmH2e3E5rfLoB6Dedt/AlJy9z9Gkn/JOkuM7tG0n2Strr7lZK2Zo8BtKmaYXf3/e7+Vnb/a0nvS7pC0nxJ67KnrZO0oFlNAmjcWR2gM7MuST+R9BdJne6+PysdkNRZZZ0eMyubWbnWedoAmmfYYTezcZLWS1rq7n8dWnN3l+SV1nP3XncvuXupo6OjoWYB1G9YYTez0RoM+h/d/fTXiR40s0lZfZKkQ81pEUAeag692eB1gqslve/uvxlS2ixpsaQV2e2mpnQ4Ahw7dixZ37t3b7J+2223Jetvv/32WfeUlzlz5iTrDz74YNVara+C5hLVfA1nnH2apJ9Les/MdmTLlmsw5H82syWS9ki6tTktAshDzbC7+3ZJ1f6L/Wm+7QBoFk6XBYIg7EAQhB0IgrADQRB2IAgucR2mb775pmpt6dKlyXW3b9+erH/wwQd19ZSHefPmJev3339/st7d3Z2sjx49+qx7QnOwZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIMKMs/f19SXrjzzySLL+8ssvV63t2bOnnpZyc9FFF1WtPfzww8l177zzzmR9zJgxdfWE9sOeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCCDPOvn79+mR99erVTdv2lClTkvVFixYl6+efn/5r6unpqVobO3Zscl3EwZ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Iwd08/wWyypD9I6pTkknrdfZWZPSDp3yQNZE9d7u4vpn5XqVTycrnccNMAKiuVSiqXyxVnXR7OSTUnJC1z97fMbLykN83spaz2W3f/j7waBdA8w5mffb+k/dn9r83sfUlXNLsxAPk6q8/sZtYl6SeS/pItutvM3jWzNWY2oco6PWZWNrPywMBApacAaIFhh93MxklaL2mpu/9V0u8k/UhStwb3/Csrrefuve5ecvdSR0dHDi0DqMewwm5mozUY9D+6+wZJcveD7n7S3U9J+r2kqc1rE0CjaobdzEzSaknvu/tvhiyfNORpN0vamX97APIynKPx0yT9XNJ7ZrYjW7Zc0iIz69bgcFyfpF80pUMAuRjO0fjtkiqN2yXH1AG0F86gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFHzq6Rz3ZjZgKQ9QxZNlHS4ZQ2cnXbtrV37kuitXnn29g/uXvH731oa9u9t3Kzs7qXCGkho197atS+J3urVqt54Gw8EQdiBIIoOe2/B209p197atS+J3urVkt4K/cwOoHWK3rMDaBHCDgRRSNjNbK6ZfWhmn5jZfUX0UI2Z9ZnZe2a2w8wKnV86m0PvkJntHLLsUjN7ycw+zm4rzrFXUG8PmNm+7LXbYWbzCuptspltM7PdZrbLzH6ZLS/0tUv01ZLXreWf2c1slKSPJP2LpH5Jb0ha5O67W9pIFWbWJ6nk7oWfgGFmMyUdlfQHd782W/aopC/cfUX2H+UEd/9Vm/T2gKSjRU/jnc1WNGnoNOOSFkj6VxX42iX6ulUteN2K2LNPlfSJu3/m7n+T9CdJ8wvoo+25+yuSvjhj8XxJ67L76zT4j6XlqvTWFtx9v7u/ld3/WtLpacYLfe0SfbVEEWG/QtLeIY/71V7zvbukLWb2ppn1FN1MBZ3uvj+7f0BSZ5HNVFBzGu9WOmOa8bZ57eqZ/rxRHKD7vunuPkXSTZLuyt6utiUf/AzWTmOnw5rGu1UqTDP+d0W+dvVOf96oIsK+T9LkIY9/kC1rC+6+L7s9JGmj2m8q6oOnZ9DNbg8V3M/ftdM03pWmGVcbvHZFTn9eRNjfkHSlmf3QzMZI+pmkzQX08T1mdnF24ERmdrGkOWq/qag3S1qc3V8saVOBvXxHu0zjXW2acRX82hU+/bm7t/xH0jwNHpH/VNK/F9FDlb7+UdI72c+uonuT9LQG39b9nwaPbSyRdJmkrZI+lvSypEvbqLf/kvSepHc1GKxJBfU2XYNv0d+VtCP7mVf0a5foqyWvG6fLAkFwgA4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgvh//v1TaNV8b54AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.8 keras로 순차 심층 신경망 구축하기\n",
        "<구축 과정>\n",
        "1. 신경망 구조, 특성 등 상세 설계 (활성화 함수, 최적화 함수, 손실 함수, 측정 방법 등)\n",
        "2. 6만 개의 사진 x_train(데이터)을 다층 신경망에 입력, 결과 확인\n",
        "3. y_train의 레이블 정보와 비교\n",
        "4. 시험/평가 (신경망의 정확도 계산)\n",
        "\n",
        "순차 신경망은 사이킷런이나 텐서플로(케라스)를 사용하는 것이 좋다."
      ],
      "metadata": {
        "id": "3-dXGQ67SJdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train / 255, x_test / 255  #입력값 정규화\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape = (28, 28)),\n",
        "    keras.layers.Dense(256, activation = 'relu'),\n",
        "    keras.layers.Dense(10, activation = 'softmax'),\n",
        "])\n",
        "\n",
        "# 학습을 위한 최적화 함수, 손실 함수등을 가진 모델을 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPjucyFRSIS0",
        "outputId": "d549aea6-5fd4-4f3a-824c-724d7d089374"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 5ms/step - loss: 0.2265 - accuracy: 0.9340\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9731\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0604 - accuracy: 0.9817\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0424 - accuracy: 0.9869\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0319 - accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f51f00d9eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 결과 모형 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr9FzmJWu5R-",
        "outputId": "3acec445-6efa-4041-c3a2-beb9c8cd9669"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "print('신경망 모델의 학습 결과: ')\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print('test 데이터의 손실값', eval_loss, 'test 데이터의 정확도', eval_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJPefFIGyJKq",
        "outputId": "d3820e82-28a3-4e66-84b7-42b074ccc2a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "신경망 모델의 학습 결과: \n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0762 - accuracy: 0.9763\n",
            "test 데이터의 손실값 0.07622060179710388 test 데이터의 정확도 0.9763000011444092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(a):\n",
        "  exp_of_a = np.exp(a)\n",
        "  sum_exp = np.sum(exp_of_a)\n",
        "  y = exp_of_a / sum_exp\n",
        "  return y\n",
        "\n",
        "a = np.array([0.5, 4.1, 2.5, 5.6, 1.2])\n",
        "print('신경망의 예측값 :', a)\n",
        "print('소프트맥스 함수의 출력 :', softmax(a))\n",
        "\n",
        "#소프트맥스 함수의 최대값\n",
        "print('소프트맥스 함수의 최대값 :', np.max(softmax(a)))\n",
        "\n",
        "#소프트맥스 함수의 입력값을 두 배로 증가시켜보자\n",
        "print(\"\\n\\n\\n\")\n",
        "a = np.array([0.5, 4.1, 2.5, 5.6, 1.2]) * 2\n",
        "print('신경망의 예측값 :', a)\n",
        "print('소프트맥스 함수의 출력 :', softmax(a))\n",
        "print('소프트맥스 함수의 최대값 :', np.max(softmax(a)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVPB9sQr1QxS",
        "outputId": "a8e3de0d-11e8-4354-f8f6-bdee4f8d2746"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "신경망의 예측값 : [0.5 4.1 2.5 5.6 1.2]\n",
            "소프트맥스 함수의 출력 : [0.00473882 0.17343248 0.03501541 0.77727047 0.00954281]\n",
            "소프트맥스 함수의 최대값 : 0.7772704668966948\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "신경망의 예측값 : [ 1.   8.2  5.  11.2  2.4]\n",
            "소프트맥스 함수의 출력 : [3.53328547e-05 4.73259126e-02 1.92910850e-03 9.50566364e-01\n",
            " 1.43281791e-04]\n",
            "소프트맥스 함수의 최대값 : 0.9505663642857384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 소프트맥스 함수는 최대값을 더욱 활성화하고 작은 값을 억제하는 효과."
      ],
      "metadata": {
        "id": "OoViaqe72c-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.11 원-핫 인코딩과 평균제곱 오차\n",
        "> softmax 출력의 최대값과 비교해볼 것\n",
        "평가 : y와 t의 차이 = 오차 => 제곱 오차의 합 SSE"
      ],
      "metadata": {
        "id": "uwNHOSZAG_h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "data = np.array([0, 1, 2, 3, 4])\n",
        "print('인코딩할 원본 데이터', data)\n",
        "encoded = to_categorical(data)\n",
        "print('원-핫 인코딩된 데이터 :')\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OLPCbfN2iL8",
        "outputId": "0f9d0fb3-95ad-4fbc-f355-2977de90f802"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩할 원본 데이터 [0 1 2 3 4]\n",
            "원-핫 인코딩된 데이터 :\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "target = np.array([0, 0, 0, 1, 0])\n",
        "y_hat = np.array([0.005, 0.173, 0.035, 0.777, 0.01])\n",
        "\n",
        "def mse(y, t):\n",
        "  return ((y-t)**2).mean()\n",
        "\n",
        "print('y_hat과 target과의 오차 :', mse(y_hat, target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq5acWvHKfzL",
        "outputId": "4e5f1fd9-584a-4e91-e640-30393236ddd3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_hat과 target과의 오차 : 0.016201599999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 신경망의 예측값이 [0.2, 0.3, 0.4, 0.01, 0.09]와 같이 정답과 크게 다르면 평균제곱 오차는 0.2556과 같이 늘어난다."
      ],
      "metadata": {
        "id": "IfdMaV9yJz9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#정답에서 많이 벗어난 other_y_hat 추정지\n",
        "other_y_hat = np.array([0.2, 0.3, 0.4, 0.01, 0.09])\n",
        "\n",
        "#other_y_hat 추정치와 정답과의 오차를 알아보자\n",
        "print('other_y_hat과 target과의 오차 :', mse( other_y_hat, target ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa5EQc_LKCB2",
        "outputId": "d6c48bfd-db64-4a06-d5c5-ce1b0341ed80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "other_y_hat과 target과의 오차 : 0.25564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정답에서 많이 벗어날 수록 큰 오차값이 나오고, 신경망의 학습도 그에 맞춰 큰 폭으로 이루어진다."
      ],
      "metadata": {
        "id": "ySHOZo_MK0Sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.12 평균 제곱오차와 크로스엔트로피(교차 엔트로피)\n",
        "- 크로스엔트로피는 분류 모델을 평가할 때보다 의미있다\n",
        "- 이를 위해 학습 데이터의 정답을 원-핫 인코딩으로 표현한다.\n",
        "- mse를 통한 오차 구하기가 가능합에도 크로스엔트로피를 사용하는 이유는, **신경망은 학습의 오류를 줄이는 과정이기 때문이다.**\n",
        "  - 벌점에 해당하는 오차값이 더 큰 크로스엔트로피 오차를 신경망의 오차로 사용하는 게 학습 속도를 더 빠르게 할 수 있음"
      ],
      "metadata": {
        "id": "anFgQ2NwLCgO"
      }
    }
  ]
}